services:
  db:
    image: postgres:16
    environment:
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: transcripts
    volumes:
      - dbdata:/var/lib/postgresql/data
      # NOTE: schema.sql is no longer applied automatically on first boot
      # Migrations are now managed by Alembic via the 'migrations' service
      # If you need to bootstrap from schema.sql for testing, apply it manually
    # Expose Postgres to the host for external clients (psql/DBeaver/etc.)
    # If port 5432 is already used on your host, change to something like "5434:5432".
    ports:
      - "5434:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  migrations:
    image: transcript-create:latest
    env_file: .env
    environment:
      DATABASE_URL: postgresql+psycopg://postgres:postgres@db:5432/transcripts
    depends_on:
      db:
        condition: service_healthy
    command: ["python3", "scripts/run_migrations.py", "upgrade"]
    restart: "no"

  api:
    build:
      context: .
      args:
        # Change to rocm6.1 or rocm6.2 if your host ROCm matches those
        ROCM_WHEEL_INDEX: https://download.pytorch.org/whl/rocm6.0
    image: transcript-create:latest
    env_file: .env
    environment:
      # Point app to the compose network Postgres
      DATABASE_URL: postgresql+psycopg://postgres:postgres@db:5432/transcripts
      # Point app to OpenSearch service inside the compose network
      OPENSEARCH_URL: http://opensearch:9200
      # Persist model caches to a mounted volume
      HF_HOME: /root/.cache/hf
      HF_HUB_CACHE: /root/.cache/hf/hub
      TRANSFORMERS_CACHE: /root/.cache/hf/transformers
      LOG_LEVEL: DEBUG
      # Disable OpenTelemetry SDK to avoid external telemetry posts
      OTEL_SDK_DISABLED: "true"
    ports:
      - "8000:8000"
    depends_on:
      db:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully
    volumes:
      - ./data:/data
      - ./cache:/root/.cache
    devices:
      - "/dev/kfd:/dev/kfd"
      - "/dev/dri:/dev/dri"
    group_add:
      - "video"

  worker:
    image: transcript-create:latest
    env_file: .env
    environment:
      DATABASE_URL: postgresql+psycopg://postgres:postgres@db:5432/transcripts
      OPENSEARCH_URL: http://opensearch:9200
      # Persist model caches to a mounted volume
      HF_HOME: /root/.cache/hf
      HF_HUB_CACHE: /root/.cache/hf/hub
      TRANSFORMERS_CACHE: /root/.cache/hf/transformers
      LOG_LEVEL: DEBUG
      # Use ROCm PyTorch whisper backend and force GPU
      WHISPER_BACKEND: "whisper"
      WHISPER_MODEL: "large-v3"
      FORCE_GPU: "true"
      # ROCm stability tweaks for some RDNA cards/drivers
      HSA_ENABLE_SDMA: "0"
      # Suppress PyTorch FutureWarnings for trusted models
      PYTHONWARNINGS: "ignore::FutureWarning"
      # Disable OpenTelemetry SDK to avoid external telemetry posts
      OTEL_SDK_DISABLED: "true"
    depends_on:
      db:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully
    command: ["python3", "-m", "worker.loop"]
    volumes:
      - ./data:/data
      - ./cache:/root/.cache
    devices:
      - "/dev/kfd:/dev/kfd"
      - "/dev/dri:/dev/dri"
    group_add:
      - "video"

  opensearch:
    image: opensearchproject/opensearch:2.12.0
    environment:
      - discovery.type=single-node
      - DISABLE_SECURITY_PLUGIN=true
      - DISABLE_INSTALL_DEMO_CONFIG=true
      - bootstrap.memory_lock=true
      - OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m
    volumes:
      - ./config/opensearch/analysis:/usr/share/opensearch/config/analysis:ro
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9200:9200"

  dashboards:
    image: opensearchproject/opensearch-dashboards:2.12.0
    environment:
      - OPENSEARCH_HOSTS=["http://opensearch:9200"]
    ports:
      - "5601:5601"
    depends_on:
      - opensearch

volumes:
  dbdata:
